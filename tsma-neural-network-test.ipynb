{"metadata":{"full-user-track-cell":"","full-user-track-date":"","kernelspec":{"display_name":"gpu","language":"python","name":"py3-tf2.0"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# ----- Csv files and paths used to classify music ----\nTRAIN_PATH = '../input/tsma-202223-music-genre-classification/train/Train/'\nTEST_PATH = '../input/tsma-202223-music-genre-classification/test/Test/'\ntest_files_csv = pd.read_csv(\"../input/tsma-202223-music-genre-classification/test/.csv\" , header=0)\ntest = pd.read_csv('../input/tsma-202223-music-genre-classification/test.csv', header=0)\ntrain = pd.read_csv('../input/tsma-202223-music-genre-classification/train.csv', header=0)\ngenres = pd.read_csv('../input/tsma-202223-music-genre-classification/genres.csv', header=0)","metadata":{"tags":[]},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Classification en utilisant le Deep Learning","metadata":{}},{"cell_type":"markdown","source":"### Class Neural Network","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn.functional as F\nfrom torch import binary_cross_entropy_with_logits, nn\nfrom torch.utils.data import DataLoader, random_split\nimport math  \n\nclass Net(nn.Module):\n    \n    def __init__(self, input):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(313*128, input)\n        self.fc2 = nn.Linear(input, 64)\n        self.fc3 = nn.Linear(64, 32)\n        self.fc4 = nn.Linear(32, 8)\n        \n    def forward(self, x):\n        x = x.view(-1, 313*128)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x","metadata":{"tags":[]},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### melspecro importé utilisé pour entrainer le NN","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n       os.remove(os.path.join(dirname, filename))","metadata":{"tags":[]},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_train_new.pickle\n#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_genres_train_new.pickle\n\n#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_test_new.pickle\n#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_filenames_test.pickle\n\nimport pickle\n\nsong_train=pickle.load(open('melspectro_songs_train_new.pickle','rb'))\ngenres_train=pickle.load(open('melspectro_genres_train_new.pickle','rb'))\n\nprint(song_train.shape, genres_train.shape)\n\nTRACK = 2 # par exemple\n\n#one song\nprint(song_train[TRACK].shape)\n# genre : one hot encoding\nprint(genres_train[TRACK])\n\n\n_songs=pickle.load(open('melspectro_songs_test_new.pickle','rb'))\n_track_id=pickle.load(open('melspectro_filenames_test.pickle','rb'))\n\nprint(_songs.shape, _track_id.shape)\n\nTRACK = 2 # par exemple\n\n#one song\nprint(_songs[TRACK].shape)\n# genre : one hot encoding\nprint(_track_id[TRACK])\n","metadata":{"tags":[]},"execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"(3995, 313, 128) (3995, 8)\n\n(313, 128)\n\n[0. 0. 1. 0. 0. 0. 0. 0.]\n\n(4002, 313, 128) (4002,)\n\n(313, 128)\n\n000190\n"}]},{"cell_type":"markdown","source":"### Préparation des données","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, TensorDataset\nfrom torch import Tensor\n\nclass CustomDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self,x_train, y_train, transform=None):\n        \"\"\"\n        Args:\n            x_train (numpy array): data to train\n            y_train (numpy array): labels\n        \"\"\"\n        self.x = x_train\n        self.y = y_train\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        label = self.y[idx]\n        x_data = self.x[idx]\n\n        if self.transform:\n            x_data = self.transform(x_data)\n            label = self.transform(label)\n\n        return x_data, label","metadata":{"tags":[]},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torchvision import transforms\n\nbatch_size = 64\nvalid_size = 0.2\nx_train, x_val, y_train, y_val = train_test_split(song_train, genres_train, test_size=valid_size)\nprint(x_train.shape)\nprint(x_val.shape)\n#x_train = x_train.reshape(-1, 1, 313, 128)\n#x_val = x_val.reshape(-1,1, 313,128)\ntrain_data = CustomDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\nfor x,y in train_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {x.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break\n\nvalid_data = CustomDataset(torch.from_numpy(x_val), torch.from_numpy(y_val))\nvalidation_dataloader = DataLoader(valid_data, batch_size=batch_size,\n                                   shuffle=True, num_workers=2)\n_songs = np.asarray(_songs)\ntest_dataloader = DataLoader(torch.Tensor(_songs), batch_size=batch_size, shuffle=True, num_workers=2)\n","metadata":{"tags":[]},"execution_count":21,"outputs":[{"name":"stdout","output_type":"stream","text":"(3196, 313, 128)\n\n(799, 313, 128)\n\nShape of X [N, C, H, W]: torch.Size([64, 313, 128])\n\nShape of y: torch.Size([64, 8]) torch.float32\n"}]},{"cell_type":"markdown","source":"### **Training**","metadata":{"tags":[]}},{"cell_type":"code","source":"from statistics import mean\nmodel = Net(128)\nprint(model)\nnb_batch = len(train_dataloader)\nprint(\"nb batch {}\".format(nb_batch))\ndef validation(model, validation_data, loss_fn):\n    model.train(False)\n    model.eval()\n    acc = {}\n    acc[\"val_loss\"] = []\n    acc[\"val_acc\"] = []\n    for i, (x, y) in enumerate(validation_data):\n        out = model(x)\n        loss = loss_fn(out, y.float())\n        print(out.shape)\n        accur = accuracy(out, y)\n        acc['val_loss'].append(loss.detach())\n        acc['val_acc'].append(accur.double())\n    epoch_loss = torch.stack([x for x in acc[\"val_loss\"]]).mean()\n    epoch_acc = torch.stack([x for x in acc[\"val_acc\"]]).mean()\n    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\ndef accuracy(prediction, y):\n    pred_y = torch.max(prediction, 1)[1].data.squeeze()\n    pred_y = F.one_hot(pred_y, num_classes=8)\n    accuracy = (pred_y == y)\n    return accuracy\n\ndef training(loss_fn, optimizer, epochs, model, train, validation_data):\n    acc_arr = []\n    loss_arr = []\n    valid_arr = []\n    model.train(True)\n    model.double()\n    for e in range(epochs):\n        for i, (x, y) in enumerate(train):\n            optimizer.zero_grad()\n            prediction = model(x)\n            loss = loss_fn(prediction, y.float())\n            loss_arr.append(loss)\n            loss.backward()\n            optimizer.step()\n            \n            acc = accuracy(prediction, y)\n            acc_arr.append(acc)\n                \n        valid = validation(model, validation_data, loss_fn)\n        valid_arr.append(valid)\n        print(\"Epoch: {} \\t loss: {:.6f} \\t acc: {:.3f}\".format(e+1, loss.data.item(), torch.mean(torch.Tensor(acc_arr))))\n        print(\"\\t\\t val loss: {:.3f}% \\t val acc: \\t {:.3f}%\".format(valid[\"val_loss\"], valid[\"val_acc\"]))\n    return acc_arr, loss_arr, valid_arr\n\ndef predict(model, test_data):\n    pred = []\n    model.train(False)\n    model.eval()\n    model.double()\n    for i, x in enumerate(test_data):\n        prediction = model(x.double())\n        pred_np = prediction.cpu().detach().numpy()\n        for n in pred_np:\n            pred.append(n)\n    return pred","metadata":{"tags":[]},"execution_count":79,"outputs":[{"name":"stdout","output_type":"stream","text":"Net(\n\n  (fc1): Linear(in_features=40064, out_features=128, bias=True)\n\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n\n  (fc3): Linear(in_features=64, out_features=32, bias=True)\n\n  (fc4): Linear(in_features=32, out_features=8, bias=True)\n\n)\n\nnb batch 50\n"}]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\nlr = 1e-3\nepochs=50\noptimizer = torch.optim.Adam(model.parameters(), lr)\nacc, loss, valid = training(loss_fn, optimizer, epochs, model, train_dataloader, validation_dataloader)","metadata":{"tags":[]},"execution_count":80,"outputs":[{"name":"stdout","output_type":"stream","text":"torch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([64, 8])\n\ntorch.Size([31, 8])\n"},{"ename":"RuntimeError","evalue":"stack expects each tensor to be equal size, but got [64, 8] at entry 0 and [31, 8] at entry 12","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/cache-twolff/ipykernel_141127/1006377599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/cache-twolff/ipykernel_141127/2729404683.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(loss_fn, optimizer, epochs, model, train, validation_data)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0macc_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mvalid_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {} \\t loss: {:.6f} \\t acc: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/cache-twolff/ipykernel_141127/2729404683.py\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(model, validation_data, loss_fn)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [64, 8] at entry 0 and [31, 8] at entry 12"]}]},{"cell_type":"code","source":"res = predict(model, test_dataloader)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sum(res[0]))\nprint(\"prediction of class for first song\")\nprint(np.argmax(sum(res[0]))+1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_data(output_prediction):\n    predictions = [np.argmax(sum(i))+1 for i in output_prediction]\n    return predictions\n\nprediction = process_data(res)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# valeurs manquantes dans le .csv\ntab = ['059684', '098565', '098568', '098569', '098571', '098559']\nidx=0\ntest[\"genre_id\"] = 1\nfor index, row in test.iterrows():\n    track_id = f'{row.track_id:06d}'\n    if track_id in tab:\n        row[\"genre_id\"] = 1\n    else:\n        row[\"genre_id\"] = prediction[idx]\n        idx+=1\n\ntest.to_csv(\"submission.csv\", encoding='utf-8', index=False)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test)","metadata":{},"execution_count":98,"outputs":[{"name":"stdout","output_type":"stream","text":"      track_id  genre_id\n\n0           10         6\n\n1          141         6\n\n2          190         6\n\n3          193         6\n\n4          194         6\n\n...        ...       ...\n\n4003    155065         6\n\n4004    155066         6\n\n4005    155141         6\n\n4006    155298         6\n\n4007    155306         6\n\n\n\n[4008 rows x 2 columns]\n"}]}]}