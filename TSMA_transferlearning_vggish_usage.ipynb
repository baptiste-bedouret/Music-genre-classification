{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeP9NnyOF8TC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16345b0-8e2a-4f3c-dfed-f6f1e36b99e3"
      },
      "source": [
        "!rm -rf sample_data\n",
        "\n",
        "# VGG shape 31x128\n",
        "!wget http://dept-info.labri.fr/~hanna/ProjetClassif/train_id_genres_vgg.pickle\n",
        "\n",
        "!wget http://dept-info.labri.fr/~hanna/ProjetClassif/test_id_vgg.pickle\n",
        "\n",
        "# Docs\n",
        "# https://github.com/tensorflow/models/tree/master/research/audioset/vggish"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-19 18:33:08--  http://dept-info.labri.fr/~hanna/ProjetClassif/train_id_genres_vgg.pickle\n",
            "Resolving dept-info.labri.fr (dept-info.labri.fr)... 147.210.9.83, 2001:660:6101:404::2:80\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dept-info.labri.fr/~hanna/ProjetClassif/train_id_genres_vgg.pickle [following]\n",
            "--2022-12-19 18:33:09--  https://dept-info.labri.fr/~hanna/ProjetClassif/train_id_genres_vgg.pickle\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63618706 (61M)\n",
            "Saving to: ‘train_id_genres_vgg.pickle’\n",
            "\n",
            "train_id_genres_vgg 100%[===================>]  60.67M  38.2MB/s    in 1.6s    \n",
            "\n",
            "2022-12-19 18:33:10 (38.2 MB/s) - ‘train_id_genres_vgg.pickle’ saved [63618706/63618706]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2022-12-19 18:33:10--  https://dept-info.labri.fr/~hanna/ProjetClassif/test_id_vgg.pickle\n",
            "Resolving dept-info.labri.fr (dept-info.labri.fr)... 147.210.9.83, 2001:660:6101:404::2:80\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63739329 (61M)\n",
            "Saving to: ‘test_id_vgg.pickle’\n",
            "\n",
            "test_id_vgg.pickle  100%[===================>]  60.79M  37.9MB/s    in 1.6s    \n",
            "\n",
            "2022-12-19 18:33:12 (37.9 MB/s) - ‘test_id_vgg.pickle’ saved [63739329/63739329]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Train dataset : list of (id, genre, embed)\n",
        "data = pickle.load(open('train_id_genres_vgg.pickle','rb'))\n",
        "\n",
        "ids = [x[0] for x in data]\n",
        "genres = [x[1] for x in data]\n",
        "embed = [x[2] for x in data]\n",
        "\n",
        "#one hot encoding\n",
        "import tensorflow as tf\n",
        "genres = [int(x)-1 for x in genres]\n",
        "genres = tf.keras.utils.to_categorical(genres)\n",
        "\n",
        "# Example\n",
        "TRACK_NUMBER = 10\n",
        "print(\"track n°\", TRACK_NUMBER)\n",
        "print(\"Song genres \", genres[TRACK_NUMBER])\n",
        "print(\"Embed shape \", embed[TRACK_NUMBER].shape)\n",
        "print(\"Embed \", embed[TRACK_NUMBER])\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.array(embed)\n",
        "y_train = np.array(genres)\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "# Test dataset : list of (id, embed)\n",
        "data = pickle.load(open('test_id_vgg.pickle','rb'))\n",
        "\n",
        "tmp = [(x[0],x[1]) for x in data if len(x[1]) == 31]\n",
        "ids = [x[0] for x in tmp]\n",
        "embed = [x[1] for x in tmp]\n",
        "\n",
        "# Example\n",
        "TRACK_NUMBER = 10\n",
        "print(\"track n°\", TRACK_NUMBER)\n",
        "print(\"Song id \", ids[TRACK_NUMBER])\n",
        "print(\"Embed shape \", embed[TRACK_NUMBER].shape)\n",
        "print(\"Embed \", embed[TRACK_NUMBER])\n",
        "\n",
        "import numpy as np\n",
        "embed = np.array(embed)\n",
        "ids = np.array(ids)\n",
        "print(embed.shape, ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3h4AaqTKEP5",
        "outputId": "b6179226-c867-49a2-c03e-962e7a1f0577"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "track n° 10\n",
            "Song genres  [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "Embed shape  (31, 128)\n",
            "Embed  [[ 4.9715251e-02  6.4623654e-03  1.4974146e-01 ...  2.5808668e-01\n",
            "   1.7034711e-01  1.9361663e-01]\n",
            " [-1.7946199e-01  4.0544292e-01 -1.4402509e-01 ... -6.0221761e-02\n",
            "   2.1952584e-02  3.1505102e-01]\n",
            " [-5.2178204e-01  4.4526982e-01  7.8287050e-02 ... -4.9954882e-01\n",
            "   1.7422524e-01  3.1353217e-01]\n",
            " ...\n",
            " [ 1.2343328e-01  7.0264429e-02  4.1037798e-05 ...  2.9932988e-01\n",
            "   3.0311149e-01 -1.6516665e-01]\n",
            " [ 2.5620168e-01 -4.7355741e-02  2.1767169e-02 ...  3.3860534e-01\n",
            "   1.7308064e-02  4.5191109e-02]\n",
            " [ 5.6809157e-02  2.3029198e-01 -3.4522653e-02 ...  6.7807639e-01\n",
            "   9.9629365e-02 -9.4960511e-02]]\n",
            "(3995, 31, 128) (3995, 8)\n",
            "track n° 10\n",
            "Song id  000534\n",
            "Embed shape  (31, 128)\n",
            "Embed  [[-0.33152917 -0.39168087 -0.04646578 ... -0.71700513 -0.12104972\n",
            "  -0.09989479]\n",
            " [-0.63577807 -0.34468648 -0.17933583 ... -1.322129   -0.10069139\n",
            "  -0.07899085]\n",
            " [-0.4593254  -0.27077848 -0.01870891 ... -0.67547345 -0.09902768\n",
            "  -0.10994059]\n",
            " ...\n",
            " [-0.389329    0.2702645   0.07406497 ... -0.47314438  0.1824584\n",
            "   0.34045923]\n",
            " [-0.4708011   0.03451473  0.10271132 ... -0.58457947  0.19917637\n",
            "  -0.11673686]\n",
            " [-0.67493904 -0.16615796  0.45589015 ... -0.7987156  -0.12373264\n",
            "  -0.3346228 ]]\n",
            "(4003, 31, 128) (4003,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **VGG**\n"
      ],
      "metadata": {
        "id": "BqO-cxF8uOQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spec-augment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJN197AFWHna",
        "outputId": "3a1993d0-ddc3-4d55-b19e-766494b4d0d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spec-augment\n",
            "  Downloading spec_augment-0.0.3-py3-none-any.whl (4.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from spec-augment) (2.9.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (4.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (0.28.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (21.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.12)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (2.9.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (2.9.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->spec-augment) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->spec-augment) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->spec-augment) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->spec-augment) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->spec-augment) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->spec-augment) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->spec-augment) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->spec-augment) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->spec-augment) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->spec-augment) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->spec-augment) (3.0.9)\n",
            "Installing collected packages: spec-augment\n",
            "Successfully installed spec-augment-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization,Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from spec_augment import SpecAugment"
      ],
      "metadata": {
        "id": "YQaQ-kiez9fL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.30)"
      ],
      "metadata": {
        "id": "FM0vWmw10i9_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train.shape=', x_train.shape)\n",
        "print('y_train.shape=', y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WuZL1zc6ygr",
        "outputId": "c575226a-9b4d-464e-adce-6afce026cbc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (2796, 31, 128)\n",
            "y_train.shape= (2796, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows , img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows , img_cols, 1)\n",
        "input_shape= (img_rows, img_cols,1)"
      ],
      "metadata": {
        "id": "8QcH6x_Y6M9-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train.shape=', x_train.shape)\n",
        "print('y_train.shape=', y_train.shape)\n",
        "print('x_test.shape=', x_test.shape)\n",
        "print('y_test.shape=', y_test.shape)\n",
        "print('input_shape=',input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3KGwnp-1Xr4",
        "outputId": "747b39c8-e0e7-4036-d57a-edf53f08acb1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (2796, 31, 128, 1)\n",
            "y_train.shape= (2796, 8)\n",
            "x_test.shape= (1199, 31, 128, 1)\n",
            "y_test.shape= (1199, 8)\n",
            "input_shape= (31, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=25\n",
        "batch_size= 5\n",
        "\n",
        "spec_augment = SpecAugment(freq_mask_param=20,\n",
        "                           time_mask_param=20)\n",
        "\n",
        "vgg_model = Sequential()\n",
        "\n",
        "vgg_model.add(spec_augment)\n",
        "\n",
        "vgg_model.add(Flatten())\n",
        "vgg_model.add(BatchNormalization())\n",
        "vgg_model.add(Dense(256, activation='relu'))\n",
        "vgg_model.add(layers.Dropout(0.25))\n",
        "vgg_model.add(BatchNormalization())\n",
        "vgg_model.add(Dense(128, activation='relu'))\n",
        "\n",
        "vgg_model.add(Dense(512, activation='relu'))\n",
        "vgg_model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "vgg_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "vgg_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tMQUQIjyciS",
        "outputId": "fab06b8a-3358-4d54-8bbe-ba86e7337794"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.5282 - accuracy: 0.4521 - val_loss: 1.1614 - val_accuracy: 0.6330\n",
            "Epoch 2/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.2829 - accuracy: 0.5522 - val_loss: 1.1162 - val_accuracy: 0.6564\n",
            "Epoch 3/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.2486 - accuracy: 0.5676 - val_loss: 1.0447 - val_accuracy: 0.6731\n",
            "Epoch 4/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.1872 - accuracy: 0.5923 - val_loss: 1.0309 - val_accuracy: 0.6856\n",
            "Epoch 5/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.2146 - accuracy: 0.5783 - val_loss: 1.0052 - val_accuracy: 0.6739\n",
            "Epoch 6/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.2064 - accuracy: 0.5798 - val_loss: 1.0026 - val_accuracy: 0.6772\n",
            "Epoch 7/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.1754 - accuracy: 0.6019 - val_loss: 1.0474 - val_accuracy: 0.6822\n",
            "Epoch 8/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.1449 - accuracy: 0.5919 - val_loss: 0.9992 - val_accuracy: 0.6881\n",
            "Epoch 9/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.1448 - accuracy: 0.5987 - val_loss: 1.0049 - val_accuracy: 0.6847\n",
            "Epoch 10/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.1212 - accuracy: 0.6077 - val_loss: 1.0098 - val_accuracy: 0.6864\n",
            "Epoch 11/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.1309 - accuracy: 0.6016 - val_loss: 0.9687 - val_accuracy: 0.6839\n",
            "Epoch 12/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.1031 - accuracy: 0.6173 - val_loss: 0.9862 - val_accuracy: 0.6906\n",
            "Epoch 13/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.1000 - accuracy: 0.6105 - val_loss: 0.9871 - val_accuracy: 0.6797\n",
            "Epoch 14/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.1192 - accuracy: 0.6037 - val_loss: 0.9966 - val_accuracy: 0.6831\n",
            "Epoch 15/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.0984 - accuracy: 0.6170 - val_loss: 1.0340 - val_accuracy: 0.6772\n",
            "Epoch 16/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.0754 - accuracy: 0.6195 - val_loss: 0.9914 - val_accuracy: 0.6897\n",
            "Epoch 17/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.0921 - accuracy: 0.6195 - val_loss: 0.9898 - val_accuracy: 0.6831\n",
            "Epoch 18/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.0503 - accuracy: 0.6398 - val_loss: 0.9803 - val_accuracy: 0.6831\n",
            "Epoch 19/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.0694 - accuracy: 0.6305 - val_loss: 1.0445 - val_accuracy: 0.6806\n",
            "Epoch 20/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.0726 - accuracy: 0.6295 - val_loss: 1.0222 - val_accuracy: 0.6722\n",
            "Epoch 21/25\n",
            "560/560 [==============================] - 4s 7ms/step - loss: 1.0458 - accuracy: 0.6381 - val_loss: 0.9758 - val_accuracy: 0.6856\n",
            "Epoch 22/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.0340 - accuracy: 0.6338 - val_loss: 1.0248 - val_accuracy: 0.6839\n",
            "Epoch 23/25\n",
            "560/560 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.6280 - val_loss: 1.0029 - val_accuracy: 0.6706\n",
            "Epoch 24/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.0337 - accuracy: 0.6445 - val_loss: 1.0252 - val_accuracy: 0.6731\n",
            "Epoch 25/25\n",
            "560/560 [==============================] - 5s 8ms/step - loss: 1.0372 - accuracy: 0.6327 - val_loss: 1.0027 - val_accuracy: 0.6906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b62e50760>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print(\"Evaluation data\")\n",
        "results = vgg_model.evaluate(x_test, y_test, batch_size=5)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB-lOpmiO2Dj",
        "outputId": "151065fc-6941-4915-cb57-14f13ee9b9c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation data\n",
            "240/240 [==============================] - 0s 2ms/step - loss: 1.0027 - accuracy: 0.6906\n",
            "test loss, test acc: [1.0027046203613281, 0.6905754804611206]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed = embed.reshape(embed.shape[0], img_rows, img_cols, 1)\n",
        "print(embed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rSSa5SDSUbM",
        "outputId": "03170810-da9f-4fa4-80dc-61d2bce33672"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4003, 31, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_y = vgg_model.predict(embed)\n",
        "predicted_y = np.argmax(predicted_y,axis=1)\n",
        "print(ids.shape)\n",
        "print(predicted_y.shape)\n",
        "\n",
        "import csv\n",
        "with open('vggish.csv', 'w', newline='') as csvfile:\n",
        "        spamwriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "        spamwriter.writerow(['track_id']+['genre_id'])\n",
        "        for ind,x in np.ndenumerate(ids):\n",
        "          csvfile.write(\"%s,%s\\n\"%(x,predicted_y[ind]+1))\n",
        "        csvfile.write(\"%s,%s\\n\"%('098559',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('098565',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('098568',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('098569',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('098571',2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JentQ-hArcC",
        "outputId": "395e0ac6-c24c-429a-81e1-922bb7870d18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 0s 3ms/step\n",
            "(4003,)\n",
            "(4003,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PW77EuvOu4fv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}