{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeP9NnyOF8TC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b2f3ec-f14c-4a22-ebd9-ddced2995e22"
      },
      "source": [
        "!rm -rf sample_data\n",
        "\n",
        "# Melspectro Hop_size 512, shape 1249x128\n",
        "#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_train.pickle\n",
        "#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_genres_train.pickle\n",
        "\n",
        "#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_test.pickle\n",
        "#!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_filenames_test.pickle\n",
        "\n",
        "# Melspectro Hop_size 2048, shape 313x128\n",
        "!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_train_new.pickle\n",
        "!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_genres_train_new.pickle\n",
        "\n",
        "!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_test_new.pickle\n",
        "!wget http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_filenames_test.pickle\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-21 11:02:13--  http://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_train_new.pickle\n",
            "Resolving dept-info.labri.fr (dept-info.labri.fr)... 147.210.9.83, 2001:660:6101:404::2:80\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_train_new.pickle [following]\n",
            "--2022-12-21 11:02:14--  https://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_train_new.pickle\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1280445598 (1.2G)\n",
            "Saving to: ‘melspectro_songs_train_new.pickle’\n",
            "\n",
            "melspectro_songs_tr 100%[===================>]   1.19G  4.98MB/s    in 2m 57s  \n",
            "\n",
            "2022-12-21 11:05:11 (6.89 MB/s) - ‘melspectro_songs_train_new.pickle’ saved [1280445598/1280445598]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2022-12-21 11:05:12--  https://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_genres_train_new.pickle\n",
            "Resolving dept-info.labri.fr (dept-info.labri.fr)... 147.210.9.83, 2001:660:6101:404::2:80\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 127995 (125K)\n",
            "Saving to: ‘melspectro_genres_train_new.pickle’\n",
            "\n",
            "melspectro_genres_t 100%[===================>] 125.00K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-12-21 11:05:12 (1.09 MB/s) - ‘melspectro_genres_train_new.pickle’ saved [127995/127995]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2022-12-21 11:05:12--  https://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_songs_test_new.pickle\n",
            "Resolving dept-info.labri.fr (dept-info.labri.fr)... 147.210.9.83, 2001:660:6101:404::2:80\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1282689182 (1.2G)\n",
            "Saving to: ‘melspectro_songs_test_new.pickle’\n",
            "\n",
            "melspectro_songs_te 100%[===================>]   1.19G  34.7MB/s    in 53s     \n",
            "\n",
            "2022-12-21 11:06:05 (23.1 MB/s) - ‘melspectro_songs_test_new.pickle’ saved [1282689182/1282689182]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2022-12-21 11:06:05--  https://dept-info.labri.fr/~hanna/ProjetClassif/melspectro_filenames_test.pickle\n",
            "Resolving dept-info.labri.fr (dept-info.labri.fr)... 147.210.9.83, 2001:660:6101:404::2:80\n",
            "Connecting to dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96195 (94K)\n",
            "Saving to: ‘melspectro_filenames_test.pickle’\n",
            "\n",
            "melspectro_filename 100%[===================>]  93.94K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-12-21 11:06:06 (1.20 MB/s) - ‘melspectro_filenames_test.pickle’ saved [96195/96195]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU_J597KGE7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c5464d-f258-4147-eab9-16199aaa6386"
      },
      "source": [
        "import pickle\n",
        "\n",
        "_songs=pickle.load(open('melspectro_songs_train_new.pickle','rb'))\n",
        "_genres=pickle.load(open('melspectro_genres_train_new.pickle','rb'))\n",
        "\n",
        "print(_songs.shape, _genres.shape)\n",
        "xtrain= _songs\n",
        "ytrain= _genres\n",
        "\n",
        "TRACK = 2 # par exemple\n",
        "\n",
        "#one song\n",
        "print(_songs[TRACK].shape)\n",
        "# genre : one hot encoding\n",
        "print(_genres[TRACK])\n",
        "\n",
        "\n",
        "_songs=pickle.load(open('melspectro_songs_test_new.pickle','rb'))\n",
        "_track_id=pickle.load(open('melspectro_filenames_test.pickle','rb'))\n",
        "\n",
        "print(_songs.shape, _track_id.shape)\n",
        "\n",
        "TRACK = 2 # par exemple\n",
        "\n",
        "#one song\n",
        "print(_songs[TRACK].shape)\n",
        "# genre : one hot encoding\n",
        "print(_track_id[TRACK])\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3995, 313, 128) (3995, 8)\n",
            "(313, 128)\n",
            "[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "(4002, 313, 128) (4002,)\n",
            "(313, 128)\n",
            "000190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deep learning**"
      ],
      "metadata": {
        "id": "4JQdX4V18cJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZOldrPb-1O9",
        "outputId": "670a8e54-a10f-485d-f01c-eb895b834463"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "mMctZwq59eWT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(xtrain, ytrain, test_size=0.30)"
      ],
      "metadata": {
        "id": "fUJGSEhfLcCo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "print('x_train.shape=', x_train.shape)\n",
        "print('x_test.shape=', x_test.shape)\n",
        "print('input_shape=',input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLZC9qxLOIQB",
        "outputId": "7692f26a-dc0f-472f-8e96-d93f9c3c49d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape= (2796, 313, 128, 1)\n",
            "x_test.shape= (1199, 313, 128, 1)\n",
            "input_shape= (313, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding = \"same\"\n",
        "epochs=50\n",
        "batch_size= 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(32 ,input_shape=input_shape , kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0))\n",
        "\n",
        "model.add(Conv2D(64 ,input_shape=input_shape , kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0))\n",
        "\n",
        "model.add(Conv2D(128 ,input_shape=input_shape , kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size, callbacks=[earlyStopping, mcp_save])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWCzfcPMAhZO",
        "outputId": "42e826ff-abfd-4276-fb0a-633212b57b4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "560/560 [==============================] - 27s 29ms/step - loss: 2.0995 - accuracy: 0.2711 - val_loss: 1.7001 - val_accuracy: 0.4103\n",
            "Epoch 2/50\n",
            "560/560 [==============================] - 14s 25ms/step - loss: 2.0501 - accuracy: 0.2500 - val_loss: 1.9131 - val_accuracy: 0.3136\n",
            "Epoch 3/50\n",
            "560/560 [==============================] - 14s 26ms/step - loss: 1.8711 - accuracy: 0.3119 - val_loss: 1.8936 - val_accuracy: 0.3561\n",
            "Epoch 4/50\n",
            "560/560 [==============================] - 15s 28ms/step - loss: 1.9343 - accuracy: 0.2722 - val_loss: 1.7822 - val_accuracy: 0.3528\n",
            "Epoch 5/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.8208 - accuracy: 0.3162 - val_loss: 3.0034 - val_accuracy: 0.2911\n",
            "Epoch 6/50\n",
            "560/560 [==============================] - 15s 26ms/step - loss: 1.8036 - accuracy: 0.3323 - val_loss: 1.6736 - val_accuracy: 0.4320\n",
            "Epoch 7/50\n",
            "560/560 [==============================] - 16s 28ms/step - loss: 1.7214 - accuracy: 0.3705 - val_loss: 1.6287 - val_accuracy: 0.4704\n",
            "Epoch 8/50\n",
            "560/560 [==============================] - 15s 26ms/step - loss: 1.7455 - accuracy: 0.3612 - val_loss: 1.6189 - val_accuracy: 0.4662\n",
            "Epoch 9/50\n",
            "560/560 [==============================] - 16s 28ms/step - loss: 1.7465 - accuracy: 0.3577 - val_loss: 1.6559 - val_accuracy: 0.4370\n",
            "Epoch 10/50\n",
            "560/560 [==============================] - 16s 28ms/step - loss: 1.7267 - accuracy: 0.3587 - val_loss: 9.3998 - val_accuracy: 0.1476\n",
            "Epoch 11/50\n",
            "560/560 [==============================] - 15s 26ms/step - loss: 1.6930 - accuracy: 0.3702 - val_loss: 1.5474 - val_accuracy: 0.4779\n",
            "Epoch 12/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.6637 - accuracy: 0.3863 - val_loss: 1.5993 - val_accuracy: 0.4570\n",
            "Epoch 13/50\n",
            "560/560 [==============================] - 16s 28ms/step - loss: 1.6089 - accuracy: 0.4217 - val_loss: 1.5664 - val_accuracy: 0.4579\n",
            "Epoch 14/50\n",
            "560/560 [==============================] - 16s 28ms/step - loss: 1.6329 - accuracy: 0.4041 - val_loss: 1.5465 - val_accuracy: 0.4679\n",
            "Epoch 15/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.6215 - accuracy: 0.4142 - val_loss: 1.6433 - val_accuracy: 0.4370\n",
            "Epoch 16/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.6044 - accuracy: 0.4160 - val_loss: 1.5998 - val_accuracy: 0.4746\n",
            "Epoch 17/50\n",
            "560/560 [==============================] - 16s 29ms/step - loss: 1.6160 - accuracy: 0.4124 - val_loss: 1.4755 - val_accuracy: 0.5029\n",
            "Epoch 18/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.5623 - accuracy: 0.4363 - val_loss: 1.5214 - val_accuracy: 0.4687\n",
            "Epoch 19/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.5656 - accuracy: 0.4299 - val_loss: 1.5471 - val_accuracy: 0.4495\n",
            "Epoch 20/50\n",
            "560/560 [==============================] - 16s 28ms/step - loss: 1.5463 - accuracy: 0.4385 - val_loss: 1.5387 - val_accuracy: 0.4712\n",
            "Epoch 21/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.5430 - accuracy: 0.4446 - val_loss: 1.5379 - val_accuracy: 0.4621\n",
            "Epoch 22/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.5011 - accuracy: 0.4517 - val_loss: 1.5687 - val_accuracy: 0.4712\n",
            "Epoch 23/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.5078 - accuracy: 0.4649 - val_loss: 1.5838 - val_accuracy: 0.4595\n",
            "Epoch 24/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.4599 - accuracy: 0.4850 - val_loss: 1.5877 - val_accuracy: 0.4612\n",
            "Epoch 25/50\n",
            "560/560 [==============================] - 16s 29ms/step - loss: 1.4283 - accuracy: 0.4903 - val_loss: 1.9936 - val_accuracy: 0.3428\n",
            "Epoch 26/50\n",
            "560/560 [==============================] - 15s 27ms/step - loss: 1.5077 - accuracy: 0.4582 - val_loss: 1.7829 - val_accuracy: 0.4462\n",
            "Epoch 27/50\n",
            "560/560 [==============================] - 16s 29ms/step - loss: 1.4209 - accuracy: 0.4943 - val_loss: 1.5609 - val_accuracy: 0.4754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcd844ff640>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print(\"Evaluation data\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=5)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "id": "9hFbdpXeZpk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3920918-6e4a-4672-8667-3775e5db65fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation data\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 1.5609 - accuracy: 0.4754\n",
            "test loss, test acc: [1.5609208345413208, 0.47539615631103516]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "songs = _songs.reshape(_songs.shape[0], img_rows, img_cols, 1)\n",
        "predicted_y = model.predict(songs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdeyFEFHQxb",
        "outputId": "6be08b8f-fe16-4b93-9527-f39f18c9b75f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 6s 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_y = np.argmax(predicted_y,axis=1)\n",
        "print(predicted_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kMOZSkTHmMN",
        "outputId": "d6de536b-e39a-4aaf-d9ae-30ca550dc829"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4002,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "with open('test.csv', 'w', newline='') as csvfile:\n",
        "        spamwriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "        \n",
        "        spamwriter.writerow(['track_id']+['genre_id'])\n",
        "        \n",
        "        for ind,x in np.ndenumerate(_track_id):\n",
        "          csvfile.write(\"%s,%s\\n\"%(x,predicted_y[ind]+1))\n",
        "        csvfile.write(\"%s,%s\\n\"%('59684',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('98565',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('98568',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('98569',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('98571',2))\n",
        "        csvfile.write(\"%s,%s\\n\"%('98559',2))"
      ],
      "metadata": {
        "id": "nFrYuhcIH5Mm"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}